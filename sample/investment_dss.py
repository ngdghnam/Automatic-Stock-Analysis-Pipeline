"""
H·ªÜ TH·ªêNG H·ªñ TR·ª¢ RA QUY·∫æT ƒê·ªäNH ƒê·∫¶U T∆Ø
Investment Decision Support System (IDSS)
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns
plt.style.use('seaborn-v0_8-darkgrid')

# Technical Analysis
import ta
from ta.trend import MACD, SMAIndicator, EMAIndicator
from ta.momentum import RSIIndicator, StochasticOscillator
from ta.volatility import BollingerBands, AverageTrueRange

# Machine Learning
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.metrics import classification_report, mean_absolute_error, mean_squared_error

# ====================================================================
# PH·∫¶N 1: THU TH·∫¨P D·ªÆ LI·ªÜU
# ====================================================================

class DataCollector:
    """Class ƒë·ªÉ thu th·∫≠p v√† t·ªïng h·ª£p d·ªØ li·ªáu t·ª´ nhi·ªÅu ngu·ªìn"""
    
    def __init__(self, symbol, start_date, end_date):
        self.symbol = symbol
        self.start_date = start_date
        self.end_date = end_date
        self.data = None
        
    def get_price_data(self):
        """L·∫•y d·ªØ li·ªáu gi√° l·ªãch s·ª≠"""
        from vnstock3 import Quote
        quote = Quote(symbol=self.symbol, source='VCI')
        df = quote.history(start=self.start_date, end=self.end_date)
        df['symbol'] = self.symbol
        return df
    
    def get_company_fundamentals(self):
        """L·∫•y d·ªØ li·ªáu c∆° b·∫£n c√¥ng ty"""
        from vnstock3 import Company
        company = Company(symbol=self.symbol, source='VCI')
        
        # Overview
        overview = company.overview()
        overview = overview.drop_duplicates(subset=['symbol'])
        
        # Financial ratios
        ratios = company.ratio_summary()
        if not ratios.empty:
            ratios['year_report'] = ratios['year_report'].astype(int)
        
        # Trading stats
        trading = company.trading_stats()
        trading = trading.drop_duplicates(subset=['symbol'])
        
        return overview, ratios, trading
    
    def get_market_data(self):
        """L·∫•y d·ªØ li·ªáu th·ªã tr∆∞·ªùng (VN-Index)"""
        from vnstock3 import Quote
        try:
            vnindex = Quote(symbol='VNINDEX', source='VCI')
            market_df = vnindex.history(start=self.start_date, end=self.end_date)
            market_df = market_df.rename(columns={
                'close': 'market_close',
                'volume': 'market_volume'
            })
            market_df = market_df[['time', 'market_close', 'market_volume']]
            return market_df
        except:
            print("‚ö†Ô∏è Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu VN-Index")
            return pd.DataFrame()
    
    def merge_all_data(self):
        """K·∫øt h·ª£p t·∫•t c·∫£ d·ªØ li·ªáu"""
        print(f"üìä Thu th·∫≠p d·ªØ li·ªáu cho {self.symbol}...")
        
        # 1. D·ªØ li·ªáu gi√°
        price_df = self.get_price_data()
        price_df['year_report'] = pd.to_datetime(price_df['time']).dt.year
        print(f"‚úì Gi√°: {len(price_df)} ng√†y")
        
        # 2. D·ªØ li·ªáu th·ªã tr∆∞·ªùng
        market_df = self.get_market_data()
        if not market_df.empty:
            price_df = pd.merge(price_df, market_df, on='time', how='left')
            print(f"‚úì Th·ªã tr∆∞·ªùng: {len(market_df)} ng√†y")
        
        # 3. D·ªØ li·ªáu c√¥ng ty
        overview, ratios, trading = self.get_company_fundamentals()
        
        # Merge overview
        if not overview.empty:
            cols_to_drop = [c for c in overview.columns 
                          if c in price_df.columns and c != 'symbol']
            overview = overview.drop(columns=cols_to_drop)
            price_df = pd.merge(price_df, overview, on='symbol', how='left')
            print(f"‚úì T·ªïng quan: {len(overview.columns)} features")
        
        # Merge ratios
        if not ratios.empty:
            cols_to_drop = [c for c in ratios.columns 
                          if c in price_df.columns and c not in ['symbol', 'year_report']]
            ratios = ratios.drop(columns=cols_to_drop)
            price_df = pd.merge(price_df, ratios, 
                              on=['symbol', 'year_report'], how='left')
            print(f"‚úì T√†i ch√≠nh: {len(ratios.columns)} features")
        
        # Merge trading
        if not trading.empty:
            cols_to_drop = [c for c in trading.columns 
                          if c in price_df.columns and c != 'symbol']
            trading = trading.drop(columns=cols_to_drop)
            price_df = pd.merge(price_df, trading, on='symbol', how='left')
            print(f"‚úì Giao d·ªãch: {len(trading.columns)} features")
        
        self.data = price_df
        print(f"\n‚úÖ T·ªïng c·ªông: {price_df.shape[0]} rows √ó {price_df.shape[1]} columns")
        return self.data


# ====================================================================
# PH·∫¶N 2: FEATURE ENGINEERING
# ====================================================================

class FeatureEngineer:
    """Class ƒë·ªÉ t·∫°o c√°c features t·ª´ d·ªØ li·ªáu th√¥"""
    
    def __init__(self, df):
        self.df = df.copy()
        
    def add_technical_indicators(self):
        """Th√™m c√°c ch·ªâ b√°o k·ªπ thu·∫≠t"""
        print("\nüîß T·∫°o Technical Indicators...")
        df = self.df.copy()
        
        # 1. Price-based features
        df['returns'] = df['close'].pct_change()
        df['log_returns'] = np.log(df['close'] / df['close'].shift(1))
        df['price_change'] = df['close'] - df['open']
        df['high_low_range'] = df['high'] - df['low']
        
        # 2. Moving Averages
        for period in [5, 10, 20, 50, 200]:
            df[f'sma_{period}'] = df['close'].rolling(window=period).mean()
            df[f'ema_{period}'] = df['close'].ewm(span=period).mean()
        
        # 3. RSI
        rsi = RSIIndicator(close=df['close'], window=14)
        df['rsi'] = rsi.rsi()
        
        # 4. MACD
        macd = MACD(close=df['close'])
        df['macd'] = macd.macd()
        df['macd_signal'] = macd.macd_signal()
        df['macd_diff'] = macd.macd_diff()
        
        # 5. Bollinger Bands
        bb = BollingerBands(close=df['close'], window=20, window_dev=2)
        df['bb_high'] = bb.bollinger_hband()
        df['bb_low'] = bb.bollinger_lband()
        df['bb_mid'] = bb.bollinger_mavg()
        df['bb_width'] = (df['bb_high'] - df['bb_low']) / df['bb_mid']
        
        # 6. Stochastic
        stoch = StochasticOscillator(high=df['high'], low=df['low'], 
                                      close=df['close'], window=14)
        df['stoch_k'] = stoch.stoch()
        df['stoch_d'] = stoch.stoch_signal()
        
        # 7. ATR (Average True Range)
        atr = AverageTrueRange(high=df['high'], low=df['low'], 
                                close=df['close'], window=14)
        df['atr'] = atr.average_true_range()
        
        # 8. Volume indicators
        df['volume_sma_20'] = df['volume'].rolling(window=20).mean()
        df['volume_ratio'] = df['volume'] / df['volume_sma_20']
        
        print(f"‚úì ƒê√£ t·∫°o {df.shape[1] - self.df.shape[1]} technical indicators")
        self.df = df
        return self
    
    def add_lag_features(self, periods=[1, 2, 3, 5, 10]):
        """Th√™m features t·ª´ qu√° kh·ª©"""
        print("\nüîß T·∫°o Lag Features...")
        df = self.df.copy()
        
        for period in periods:
            df[f'close_lag_{period}'] = df['close'].shift(period)
            df[f'volume_lag_{period}'] = df['volume'].shift(period)
            df[f'returns_lag_{period}'] = df['returns'].shift(period)
        
        print(f"‚úì ƒê√£ t·∫°o {len(periods) * 3} lag features")
        self.df = df
        return self
    
    def add_rolling_features(self, windows=[5, 10, 20]):
        """Th√™m rolling statistics"""
        print("\nüîß T·∫°o Rolling Features...")
        df = self.df.copy()
        
        for window in windows:
            # Rolling statistics for price
            df[f'close_rolling_mean_{window}'] = df['close'].rolling(window).mean()
            df[f'close_rolling_std_{window}'] = df['close'].rolling(window).std()
            df[f'close_rolling_min_{window}'] = df['close'].rolling(window).min()
            df[f'close_rolling_max_{window}'] = df['close'].rolling(window).max()
            
            # Rolling statistics for volume
            df[f'volume_rolling_mean_{window}'] = df['volume'].rolling(window).mean()
            
            # Volatility
            df[f'volatility_{window}'] = df['returns'].rolling(window).std()
        
        print(f"‚úì ƒê√£ t·∫°o {len(windows) * 6} rolling features")
        self.df = df
        return self
    
    def add_time_features(self):
        """Th√™m time-based features"""
        print("\nüîß T·∫°o Time Features...")
        df = self.df.copy()
        
        df['time'] = pd.to_datetime(df['time'])
        df['day_of_week'] = df['time'].dt.dayofweek
        df['day_of_month'] = df['time'].dt.day
        df['month'] = df['time'].dt.month
        df['quarter'] = df['time'].dt.quarter
        df['is_month_start'] = df['time'].dt.is_month_start.astype(int)
        df['is_month_end'] = df['time'].dt.is_month_end.astype(int)
        df['is_quarter_start'] = df['time'].dt.is_quarter_start.astype(int)
        df['is_quarter_end'] = df['time'].dt.is_quarter_end.astype(int)
        
        print(f"‚úì ƒê√£ t·∫°o 8 time features")
        self.df = df
        return self
    
    def create_target_variable(self, horizon=1, method='classification', threshold=0.01):
        """
        T·∫°o bi·∫øn target cho d·ª± ƒëo√°n
        
        Parameters:
        -----------
        horizon: int - D·ª± ƒëo√°n sau bao nhi√™u ng√†y
        method: str - 'classification' ho·∫∑c 'regression'
        threshold: float - Ng∆∞·ª°ng ƒë·ªÉ ph√¢n lo·∫°i tƒÉng/gi·∫£m (cho classification)
        """
        print(f"\nüéØ T·∫°o Target Variable (method={method}, horizon={horizon})...")
        df = self.df.copy()
        
        if method == 'classification':
            # Binary: TƒÉng (1) ho·∫∑c Gi·∫£m (0)
            df['future_returns'] = df['close'].shift(-horizon) / df['close'] - 1
            df['target'] = (df['future_returns'] > threshold).astype(int)
            print(f"‚úì Target: 0=Gi·∫£m, 1=TƒÉng (threshold={threshold*100}%)")
            print(f"  - TƒÉng: {df['target'].sum()} ({df['target'].mean()*100:.1f}%)")
            print(f"  - Gi·∫£m: {(1-df['target']).sum()} ({(1-df['target'].mean())*100:.1f}%)")
            
        elif method == 'regression':
            # D·ª± ƒëo√°n gi√° t∆∞∆°ng lai
            df['target'] = df['close'].shift(-horizon)
            print(f"‚úì Target: Gi√° sau {horizon} ng√†y")
        
        self.df = df
        return self
    
    def get_processed_data(self):
        """Tr·∫£ v·ªÅ d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω"""
        return self.df


# ====================================================================
# PH·∫¶N 3: PH√ÇN T√çCH D·ªÆ LI·ªÜU
# ====================================================================

class DataAnalyzer:
    """Class ƒë·ªÉ ph√¢n t√≠ch v√† visualize d·ªØ li·ªáu"""
    
    def __init__(self, df):
        self.df = df
        
    def data_summary(self):
        """T·ªïng quan v·ªÅ d·ªØ li·ªáu"""
        print("\n" + "="*70)
        print("üìä DATA SUMMARY")
        print("="*70)
        
        print(f"\nüìè Shape: {self.df.shape[0]} rows √ó {self.df.shape[1]} columns")
        print(f"üìÖ Time range: {self.df['time'].min()} to {self.df['time'].max()}")
        print(f"üí∞ Price range: {self.df['close'].min():.2f} - {self.df['close'].max():.2f}")
        
        # Missing values
        missing = self.df.isnull().sum()
        missing_pct = (missing / len(self.df) * 100).round(2)
        missing_df = pd.DataFrame({
            'Missing': missing,
            'Percent': missing_pct
        })
        missing_df = missing_df[missing_df['Missing'] > 0].sort_values('Missing', ascending=False)
        
        if len(missing_df) > 0:
            print(f"\n‚ö†Ô∏è Missing values: {len(missing_df)} columns")
            print(missing_df.head(10))
        else:
            print("\n‚úÖ No missing values")
        
        return missing_df
    
    def plot_price_and_indicators(self, figsize=(15, 12)):
        """V·∫Ω bi·ªÉu ƒë·ªì gi√° v√† c√°c ch·ªâ b√°o"""
        fig, axes = plt.subplots(4, 1, figsize=figsize)
        
        # 1. Price and Moving Averages
        axes[0].plot(self.df['time'], self.df['close'], label='Close', linewidth=2)
        if 'sma_20' in self.df.columns:
            axes[0].plot(self.df['time'], self.df['sma_20'], label='SMA 20', alpha=0.7)
        if 'sma_50' in self.df.columns:
            axes[0].plot(self.df['time'], self.df['sma_50'], label='SMA 50', alpha=0.7)
        axes[0].set_title('Price Chart with Moving Averages', fontsize=12, fontweight='bold')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)
        
        # 2. Volume
        axes[1].bar(self.df['time'], self.df['volume'], alpha=0.5)
        axes[1].set_title('Trading Volume', fontsize=12, fontweight='bold')
        axes[1].grid(True, alpha=0.3)
        
        # 3. RSI
        if 'rsi' in self.df.columns:
            axes[2].plot(self.df['time'], self.df['rsi'])
            axes[2].axhline(y=70, color='r', linestyle='--', alpha=0.5)
            axes[2].axhline(y=30, color='g', linestyle='--', alpha=0.5)
            axes[2].set_title('RSI (Relative Strength Index)', fontsize=12, fontweight='bold')
            axes[2].set_ylim(0, 100)
            axes[2].grid(True, alpha=0.3)
        
        # 4. MACD
        if 'macd' in self.df.columns:
            axes[3].plot(self.df['time'], self.df['macd'], label='MACD')
            axes[3].plot(self.df['time'], self.df['macd_signal'], label='Signal')
            axes[3].bar(self.df['time'], self.df['macd_diff'], label='Histogram', alpha=0.3)
            axes[3].set_title('MACD', fontsize=12, fontweight='bold')
            axes[3].legend()
            axes[3].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
    
    def correlation_analysis(self, top_n=20):
        """Ph√¢n t√≠ch correlation"""
        # Ch·ªçn c√°c features s·ªë
        numeric_cols = self.df.select_dtypes(include=[np.number]).columns
        
        if 'target' in numeric_cols:
            # Correlation v·ªõi target
            corr_with_target = self.df[numeric_cols].corr()['target'].abs().sort_values(ascending=False)
            
            print("\n" + "="*70)
            print(f"üìä TOP {top_n} FEATURES T∆Ø∆†NG QUAN V·ªöI TARGET")
            print("="*70)
            print(corr_with_target.head(top_n))
            
            # Visualize
            plt.figure(figsize=(10, 8))
            corr_with_target.head(top_n).plot(kind='barh')
            plt.title(f'Top {top_n} Features Correlated with Target', fontsize=12, fontweight='bold')
            plt.xlabel('Absolute Correlation')
            plt.tight_layout()
            plt.show()
            
            return corr_with_target
        else:
            print("‚ö†Ô∏è Target variable ch∆∞a ƒë∆∞·ª£c t·∫°o")
            return None


# ====================================================================
# PH·∫¶N 4: M√î H√åNH D·ª∞ ƒêO√ÅN
# ====================================================================

class PredictionModel:
    """Class ƒë·ªÉ training v√† ƒë√°nh gi√° m√¥ h√¨nh"""
    
    def __init__(self, df):
        self.df = df
        self.model = None
        self.scaler = StandardScaler()
        self.feature_names = None
        
    def prepare_data(self, test_size=0.2, features_to_exclude=None):
        """
        Chu·∫©n b·ªã d·ªØ li·ªáu cho training
        """
        print("\n" + "="*70)
        print("üîß CHU·∫®N B·ªä D·ªÆ LI·ªÜU CHO TRAINING")
        print("="*70)
        
        df = self.df.copy()
        
        # Lo·∫°i b·ªè c√°c d√≤ng c√≥ target = NaN
        df = df.dropna(subset=['target'])
        print(f"‚úì Sau khi lo·∫°i NaN: {len(df)} samples")
        
        # X√°c ƒë·ªãnh features v√† target
        if features_to_exclude is None:
            features_to_exclude = ['time', 'symbol', 'target', 'future_returns']
        
        # Ch·ªâ l·∫•y c√°c c·ªôt s·ªë
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        feature_cols = [col for col in numeric_cols 
                       if col not in features_to_exclude]
        
        X = df[feature_cols].copy()
        y = df['target'].copy()
        
        # X·ª≠ l√Ω missing values trong features
        X = X.fillna(method='ffill').fillna(method='bfill').fillna(0)
        
        print(f"‚úì Features: {X.shape[1]} columns")
        print(f"‚úì Target: {y.shape[0]} samples")
        print(f"‚úì Target distribution: {y.value_counts().to_dict()}")
        
        # Split data (time-series aware)
        split_idx = int(len(X) * (1 - test_size))
        X_train = X.iloc[:split_idx]
        X_test = X.iloc[split_idx:]
        y_train = y.iloc[:split_idx]
        y_test = y.iloc[split_idx:]
        
        # Scale features
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        self.feature_names = feature_cols
        
        print(f"\n‚úì Train set: {X_train.shape[0]} samples")
        print(f"‚úì Test set: {X_test.shape[0]} samples")
        
        return X_train_scaled, X_test_scaled, y_train, y_test
    
    def train_model(self, X_train, y_train, model_type='random_forest'):
        """Training m√¥ h√¨nh"""
        print(f"\nü§ñ TRAINING MODEL: {model_type.upper()}")
        print("="*70)
        
        if model_type == 'random_forest':
            self.model = RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )
        
        self.model.fit(X_train, y_train)
        print("‚úÖ Training completed!")
        
        return self.model
    
    def evaluate_model(self, X_test, y_test):
        """ƒê√°nh gi√° m√¥ h√¨nh"""
        print("\n" + "="*70)
        print("üìä M√î H√åNH ƒê√ÅNH GI√Å")
        print("="*70)
        
        # Predictions
        y_pred = self.model.predict(X_test)
        
        # Classification report
        print("\n" + classification_report(y_test, y_pred, 
                                          target_names=['Gi·∫£m', 'TƒÉng']))
        
        # Feature importance
        if hasattr(self.model, 'feature_importances_'):
            feature_imp = pd.DataFrame({
                'feature': self.feature_names,
                'importance': self.model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            print("\nüìä TOP 20 IMPORTANT FEATURES:")
            print(feature_imp.head(20))
            
            # Plot
            plt.figure(figsize=(10, 8))
            feature_imp.head(20).plot(x='feature', y='importance', kind='barh')
            plt.title('Top 20 Feature Importances', fontsize=12, fontweight='bold')
            plt.xlabel('Importance')
            plt.tight_layout()
            plt.show()
        
        return y_pred


# ====================================================================
# MAIN EXECUTION
# ====================================================================

def main():
    """H√†m ch√≠nh ƒë·ªÉ ch·∫°y to√†n b·ªô pipeline"""
    
    print("="*70)
    print(" H·ªÜ TH·ªêNG H·ªñ TR·ª¢ RA QUY·∫æT ƒê·ªäNH ƒê·∫¶U T∆Ø".center(70))
    print(" Investment Decision Support System (IDSS)".center(70))
    print("="*70)
    
    # Config
    SYMBOL = "ACB"
    END_DATE = datetime.now().strftime('%Y-%m-%d')
    START_DATE = (datetime.now() - timedelta(days=730)).strftime('%Y-%m-%d')  # 2 nƒÉm
    
    print(f"\nüìå Symbol: {SYMBOL}")
    print(f"üìÖ Period: {START_DATE} to {END_DATE}")
    
    # Step 1: Thu th·∫≠p d·ªØ li·ªáu
    collector = DataCollector(SYMBOL, START_DATE, END_DATE)
    data = collector.merge_all_data()
    
    # Step 2: Feature Engineering
    engineer = FeatureEngin